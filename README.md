# SP-500 Stock Data ~ Machine Learning Model

Samantha Miller 
Nancy Pineda
Kanak Somani
Kevin Xu
Samson Cheffa

## Purpose
The purpose of this analysis was to analyze treads in 20 popular S&P 500 Stocks.

## Processes

### Data:
The data came from Kaggle.com (link to Kaggle)
It was a CSV file that contained S&P 500 stock data from the last 10 years. The original file contained more than a million rows of data. Due to this, we introduced bias in picking 20 stocks to manage the data. 
The ending result was 20 stocks in a CSV file of about 55,000 rows. The information that was given to us included stock symbols, trading date, open, close, volume, etc.
Additionally, we had a CSV file that contained company data for each of the 20 stocks included above.

### Cleaning

Before visualizing, storing, or using our data for machine learning, we needed to make sure to do some cleaning and check the data types. 
We checked the datatypes to make sure all the columns were in the correct types we needed to move forward. We decided for this data it was important for us to keep duplicates, so that was not part of the cleaning process.
We identified the unique symbols for each stock to make it easier to identify later on. We checked for null values and dropped those.

### Visualizations

[link to visulizations](https://public.tableau.com/app/profile/zixuan.xu)

[link to dashboard](https://public.tableau.com/views/Dashboard_16747067831160/Dashboard1?:language=en-GB&publish=yes&:display_count=n&:origin=viz_share_link)

### Database

For this project we decided to use PostgreSQL for our relational database system. We created a folder that consists of tables and their predefined relationships. Each CSV file's data will be loaded into a table. We will create tables and define relationships as we progress through this project. With one local server, the database was created and stored.

## Machine Learning Model

## Results

## Summary

## Resources
